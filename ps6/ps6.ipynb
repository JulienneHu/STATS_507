{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91fb642",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"ps6.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc827ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec28ce8",
   "metadata": {},
   "source": [
    "## Question 1: Down with `for` loops\n",
    "Each of the problems below contains a function that uses `for` loops to perform a certain operation on arrays. Your job is to rewrite these function using only Numpy array manipulations and library functions (e.g. `np.xxx()`). Do not use any `for` or `while` loops, iterators, generators, or list comprehensions in your solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc35c77",
   "metadata": {},
   "source": [
    "**1(a)** (3 pts) Return all of the rows of the integer matrix `A` where where each entry of the row is distinct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea069524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_rows_py(A):\n",
    "    'Return all rows of A that have completely distinct entries.'\n",
    "    return np.array([a for a in A if len(set(a)) == len(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1017eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.eye(5)\n",
    "distinct_rows_py(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103195fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(9).reshape(3, 3)\n",
    "distinct_rows_py(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 4, 4],\n",
    "    [5, 6, 6]])\n",
    "distinct_rows_py(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952cb7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distinct_rows_np(A):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c9e77",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f90a2d6",
   "metadata": {},
   "source": [
    "**1(b)** (3 pts) Given a vector $v$ of length $n$, and an integer $0<k<n$, return the matrix\n",
    "```\n",
    "[[v[0], ..., v[k-1]],\n",
    " [v[1], ..., v[k]  ],\n",
    " [v[2], ..., v[k+1]],\n",
    " [ .     .       . ],\n",
    " [ .     .       . ],\n",
    " [ .     .       . ],\n",
    " [v[n-k+1, ..., v[n]]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71371332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_stack_py(v, k):\n",
    "    \"Stack sliding windows of v of length k.\"\n",
    "    rows = []\n",
    "    for i in range(len(v) - k + 1):\n",
    "        rows.append(v[i : (i + k)])\n",
    "    return np.array(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3719346",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_stack_py(np.array([1, 2, 3, 4, 5]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617bb90b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sliding_stack_np(v, k):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfcd89",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52de454",
   "metadata": {},
   "source": [
    "**1(c)** (3 pts) Given a vector of non-negative integers `v`, with `max(v) = m`, return a vector `c` of length `m + 1` such that `c[i]` is the number of times that the integer `i` appears in `v`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_count_py(v):\n",
    "    m = max(v)\n",
    "    ret = np.zeros(m + 1, int)\n",
    "    for vv in v:\n",
    "        ret[vv] += 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([0, 0, 1, 1, 2, 2, 2, 3, 4])\n",
    "digit_count_py(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f1fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def digit_count_np(v):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ccaef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d983e3",
   "metadata": {},
   "source": [
    "**1(d)** (3 pts) Call a square $n\\times n$ matrix $A$ *countersymmetric* if $A_{ij} = A_{n-j,n-i}$ for all $i$ and $j$. An example of such a matrix is:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "4 & 3 & 2 & 1 & 0\\\\\n",
    "8 & 7 & 6 & 5 & 1\\\\\n",
    "11 & 10 & 9 & 6 & 2\\\\\n",
    "13 & 12 & 10 & 7 & 3\\\\\n",
    "14 & 13 & 11 & 8 & 4\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Write a function `is_countersym` that checks this property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_countersym_py(A):\n",
    "    \"Returns True if A is countersymmetric\"\n",
    "    n = A.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if A[i, j] != A[n - j - 1, n - i - 1]:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_matrix = np.array([[ 4,  3,  2,  1,  0], [ 8,  7,  6,  5,  1], [11, 10,  9,  6,  2], [13, 12, 10,  7,  3], [14, 13, 11,  8,  4]])\n",
    "is_countersym_py(cs_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65726af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_countersym_np(A):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052a86b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab6a8a",
   "metadata": {},
   "source": [
    "**1(e)** (5 pts extra credit) [Sudoku](https://en.wikipedia.org/wiki/Sudoku) is a number game played on a $9\\times 9$ grid, arranged into nine $3\\times 3$ subgrids. In order to win Sudoku, you must fill in the numbers 1-9 exactly once in every row, column, and $3\\times 3$ subgrid. Here is an example of a winning solution:\n",
    "\n",
    "![sudoku](sudoku_solved.png)\n",
    "\n",
    "*Generalized Sudoku* is played on an $n^2 \\times n^2$ grid, arranged into $n^2$ subgrids of size $n\\times n$. A winning solution contains the numbers 1-$n$ exactly once in every row, column, and $n\\times n$ subgrid.\n",
    "\n",
    "Write a function that takes a $n^2\\times n^2$ integer array and returns `True` if it is a winning (generalized) Sudoku solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sudoku_win_py(A):\n",
    "    \"Returns True if A is a winning Sudoku board\"\n",
    "    import math\n",
    "    import itertools\n",
    "\n",
    "    n = math.isqrt(A.shape[0])\n",
    "    s = set(range(1, n ** 2 + 1))\n",
    "    horiz, vert = [all(set(row) == s for row in M) for M in (A, A.T)]\n",
    "    if not (horiz and vert):\n",
    "        return False\n",
    "    for h, v in itertools.product(range(0, n * n, n), repeat=2):\n",
    "        block = A[h : h + n, v : v + n]\n",
    "        if set(block.flat) != s:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_board = [[3, 1, 6, 2, 4, 9, 7, 8, 5], \n",
    "              [2, 7, 8, 3, 6, 5, 9, 1, 4], \n",
    "              [4, 9, 5, 7, 8, 1, 6, 2, 3], \n",
    "              [8, 5, 1, 9, 7, 4, 3, 6, 2], \n",
    "              [9, 2, 3, 8, 1, 6, 4, 5, 7], \n",
    "              [6, 4, 7, 5, 3, 2, 1, 9, 8], \n",
    "              [7, 6, 2, 1, 5, 3, 8, 4, 9], \n",
    "              [1, 3, 9, 4, 2, 8, 5, 7, 6], \n",
    "              [5, 8, 4, 6, 9, 7, 2, 3, 1]]\n",
    "sudoku_win_py(np.array(good_board, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a533f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_board = np.arange(81).reshape(9, 9)\n",
    "sudoku_win_py(bad_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7b889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sudoku_win_np(A):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533679d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"1e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe521db3",
   "metadata": {},
   "source": [
    "## Question 2: $k$-means clustering\n",
    "\n",
    "$k$-means is a fundamental algorithm for clustering multivariate data. The inputs to the algorithm are:\n",
    "- An $n\\times p$ data matrix $X$ consisting of $n$ observations of a $p$-dimensional feature vector, and\n",
    "- A $k\\times p$ matrix $C$ containing initial guesses for each $k$ cluster centers.\n",
    "\n",
    "The algorithm proceeds by iteratively a) assigning each point to the nearest cluster center, and b) recomputing the cluster centers as the mean of all of the currently assigned points. Here is a partial implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537dd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, C):\n",
    "    \"\"\"\n",
    "    K-means algorithm.\n",
    "\n",
    "    Args:\n",
    "        - X: ndarray, shape (n, p), n observations of p-dimensional feature vector\n",
    "        - C: ndarray, shape (k, p), k initial cluster centers\n",
    "\n",
    "    Returns:\n",
    "        Tuple of length two:\n",
    "        The first entry is integer ndarray, shape (n), cluster assignments for each data point\n",
    "        The second entry is ndarray, shape (k, p), centers of each cluster\n",
    "    \"\"\"\n",
    "    assert X.shape[1] == C.shape[1]  # p should match\n",
    "    while True:\n",
    "        new_assignments = nearest_cluster(X, C)\n",
    "        try:\n",
    "            if np.all(new_assignments == assignments):\n",
    "                # converged\n",
    "                return assignments, C\n",
    "        except NameError:  # first iteration, no assignments\n",
    "            pass \n",
    "        assignments = new_assignments\n",
    "        C = compute_centroids(X, assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe63eb",
   "metadata": {},
   "source": [
    "You will finish implementing this algorithm by completing the missing functions `nearest_cluster()` and `compute_centroids()` below. Note: as in the Question 1, do not use any loops, iterators, or comprehensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2251e0",
   "metadata": {},
   "source": [
    "**2(a)** (3 pts) Implement the function `nearest_cluster`. It should take two array arguments, the data points `X` and the cluster centers `C`, and return an integer array giving the index in `C` which is nearest to each point in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdca0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nearest_cluster(X, C):\n",
    "    \"\"\"\n",
    "    For each point in X, find the nearest point in C.\n",
    "\n",
    "    Args:\n",
    "        X: ndarray, shape (n, p), n points of dimension p.\n",
    "        C: ndarray, shape (k, p), k points of dimension p.\n",
    "\n",
    "    Returns:\n",
    "        Integer array of length n, [j[1], j[2], ..., j[n]], such that |X[i] - C[j[i]]| <= |X[i] - C[ell]| for 1 <= ell <= k.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da119ee7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505d257",
   "metadata": {},
   "source": [
    "**2(b)** (3 pts) Implement the function `compute_centroids`. It should take two array arguments, the data points `X` and the assignment array `a`, and return an $k \\times p$ array containing the cluster centroids (averages) for each point assigned to cluster $0, \\dots, k-1$. (You may assume that every entry of $a$ is between $0$ and $k-1$, inclusive.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8688b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_centroids(X, a):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45332a6c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ba31e",
   "metadata": {},
   "source": [
    "**2(c)** (5 pts.) The performance of the $k$-means algorithm is known to depend heavily on the starting point (the initial clusters `C` passed in as the second argument.) In some cases, using a \"good\" starting point can dramatically improve the performance of the algorithm.\n",
    "\n",
    "The $k$-means++ algorithm is designed to find such a good starting point. [According to Wikipedia](https://en.wikipedia.org/wiki/K-means%2B%2B), the steps of $k$-means++ are:\n",
    "\n",
    "1. Choose one center uniformly at random among the data points.\n",
    "2. For each data point $x$ not chosen yet, compute $D(x)$, the distance between $x$ and the nearest center that has already been chosen.\n",
    "3. Choose one new data point at random as a new center, using a weighted probability distribution where a point $x$ is chosen with probability proportional to $D(x)^2$.\n",
    "4. Repeat Steps 2 and 3 until $k$ centers have been chosen.\n",
    "\n",
    "Implement this algorithm using the skeleton provided below. As before, your implementation should only use Numpy functions--no additional loops or comprehensions. \n",
    "\n",
    "**Note**: To ensure reproducibility, the parts of the algorithm that rely on ranndomness are provided for you. Your job is to fill in the missing lines necessary to complete the algoritm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe3cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeanspp(X, k, rng):\n",
    "    \"\"\"\n",
    "    k-means++ algorithm.\n",
    "\n",
    "    Args:\n",
    "        - X: ndarray, shape (n, p), as above.\n",
    "        - k, the number of clusters.\n",
    "        - rng: instance of np.random.Generator().\n",
    "\n",
    "    Returns:\n",
    "        ndarray, shape (k, p), cluster centers.\n",
    "    \"\"\"\n",
    "    n, p = X.shape\n",
    "    C = np.zeros((k, p))\n",
    "    # step 1\n",
    "    j = rng.choice(n)\n",
    "    C[0] = X[j]\n",
    "    for i in range(1, k):\n",
    "        ...\n",
    "        # step 3\n",
    "        j = rng.choice(n, p=w)\n",
    "        C[i] = X[j]\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0858b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1613b2",
   "metadata": {},
   "source": [
    "**2(d)** (2 pts) In order to measure how good a clustering is, we can define the *within-class variance* \n",
    "\n",
    "$$ V(\\mathbf{X}, \\mathbf{a}, \\mathbf{C}) = \\sum_{i=1}^n \\| \\mathbf{x}_i - \\mathbf{c}_{a_i} \\|^2,$$\n",
    "\n",
    "where the $i$-th element of $\\mathbf{a}=\\{a_1,\\dots,a_n\\}$ is the cluster assignment of observation $i$, and $\\mathbf{C}=(\\mathbf{c}_1,\\dots,\\mathbf{c}_k)$ are the centers of each cluster. Thus, $V(\\mathbf{X}, \\mathbf{a}, \\mathbf{C})$ is the sum of the squared distance from each data point to the center of its assigned cluster.\n",
    "\n",
    "Implement this function. (Again, no loops, just use Numpy functions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e749a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def V(X, a, C):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe873da6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91edbb67",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**2(e)** (5 pts) Recall from lecture the file `mnist.npz`, which contains the labeled image data for handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load(\"mnist.npz\")\n",
    "mnist[\"images\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1fe85f",
   "metadata": {},
   "source": [
    "We will experiment with clustering these data. For memory and performance reasons, we will only look at the first 1000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist[\"images\"][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384137e",
   "metadata": {},
   "source": [
    "Which performs better, $k$-means++ or random initialization? Do the clusters make sense to you? How do the clusters relate to the true labels given in `mnist['labels']`? What are some examples of images where the clustering is nearly ambiguous (meaning they were almost part of another cluster?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a857946",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd6b98e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33067fc2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 3: Working with pandas DataFrames\n",
    "\n",
    "In this problem, you'll get practice working with pandas `DataFrames`, reading\n",
    "them into and out of memory, changing their contents and performing\n",
    "aggregation operations. We'll use the file `iris.csv` included with this problem set to practice.\n",
    "**Note:** for the sake of consistency, please the CSV included with the problem set, and not one from elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cfb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e2ec8",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**3(a)** (2 pts) Read the data into a variable called `iris`. How many data points are\n",
    "    there in this data set? What are the data types of the columns? What\n",
    "    are the column names? The column names correspond to flower species\n",
    "    names, as well as four basic measurements one can make of a flower:\n",
    "    the width and length of its petals and the width and length of its\n",
    "    sepal (the part of the pant that supports and protects the flower\n",
    "    itself). How many species of flower are included in the data? Show your work by including the\n",
    "    pandas commands you used to figure out the answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befddbec",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebfa53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ca292",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**3(b)** It is now known that this dataset contains errors\n",
    "    in two of its rows (see the documentation at\n",
    "    <https://archive.ics.uci.edu/ml/datasets/Iris>). Using 1-indexing,\n",
    "    these errors are in the 35th and 38th rows. The 35th row should read\n",
    "    `4.9,3.1,1.5,0.2,\"setosa\"`, \n",
    "    where the fourth feature is incorrect as it appears in the file,\n",
    "    and the 38th row should read `4.9,3.6,1.4,0.1,\"setosa\"`, where the second and third features\n",
    "    are incorrect as they appear in the file. Correct these entries of\n",
    "    your DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4ca38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272f152",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**3(c)** The iris dataset is commonly used in machine learning as a\n",
    "        proving ground for clustering and classification algorithms.\n",
    "        Some researchers have found it useful to use two additional features,\n",
    "        called *Petal ratio* and *Sepal ratio*,\n",
    "        defined as the ratio of the petal length to petal width\n",
    "        and the ratio of the sepal length to sepal width, respectively.\n",
    "        Add two columns to your DataFrame corresponding to these two\n",
    "        new features.\n",
    "        Name these columns\n",
    "        `Petal.Ratio` and `Sepal.Ratio`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aae37e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abaf41",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**3(d)** (2 pts)\n",
    "Use a pandas aggregate operation to determine the\n",
    "        mean, median, minimum, maximum and standard deviation of the\n",
    "        petal and sepal ratio for each of the three species in the data set.\n",
    "        **Note**: you should be able to get all five numbers in a single\n",
    "        table (indeed, in a single line of code)\n",
    "        using a well-chosen group-by or aggregate operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecfc52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804d9f4",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e958f7d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b736da5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58a1c4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Upload this .zip file to Gradescope for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd5526",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b778f",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "otter": {
   "tests": {
    "1a": {
     "name": "1a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> A = np.eye(5)\n>>> np.testing.assert_allclose(distinct_rows_np(A), np.empty([0, 5]))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> A = np.array([[1, 2, 3], [4, 4, 4], [5, 6, 6]])\n>>> np.testing.assert_allclose(distinct_rows_np(A), np.array([[1, 2, 3]]))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1b": {
     "name": "1b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.testing.assert_allclose(sliding_stack_np(np.array([1, 2, 3, 4, 5]), 3), np.array([[1, 2, 3],[2, 3, 4],[3, 4, 5]]))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.testing.assert_allclose(sliding_stack_np(np.array([1, 2, 3, 4, 5]), 5), np.array([[1, 2, 3, 4, 5]]))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1c": {
     "name": "1c",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> v = np.array([0, 0, 1, 1, 2, 2, 2, 3, 4])\n>>> np.testing.assert_allclose(digit_count_np(v), np.array([2, 2, 3, 1, 1]))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> v = np.array([0, 0, 0, 0, 2, 2, 2, 3, 4])\n>>> np.testing.assert_allclose(digit_count_np(v), np.array([4, 0, 3, 1, 1]))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1d": {
     "name": "1d",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> cs_matrix = np.array([[ 4,  3,  2,  1,  0], [ 8,  7,  6,  5,  1], [11, 10,  9,  6,  2], [13, 12, 10,  7,  3], [14, 13, 11,  8,  4]])\n>>> is_countersym_np(cs_matrix)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> cs_matrix = np.array([[ 4,  3,  2,  1,  0], [ 8,  7,  5,  5,  1], [11, 10,  9,  6,  2], [13, 12, 10,  7,  3], [14, 13, 11,  8,  4]])\n>>> is_countersym_np(cs_matrix)\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1e": {
     "name": "1e",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> good_board_3x3 = [   \n...         [3, 1, 6, 2, 4, 9, 7, 8, 5],\n...         [2, 7, 8, 3, 6, 5, 9, 1, 4],\n...         [4, 9, 5, 7, 8, 1, 6, 2, 3],\n...         [8, 5, 1, 9, 7, 4, 3, 6, 2],\n...         [9, 2, 3, 8, 1, 6, 4, 5, 7],\n...         [6, 4, 7, 5, 3, 2, 1, 9, 8],\n...         [7, 6, 2, 1, 5, 3, 8, 4, 9],\n...         [1, 3, 9, 4, 2, 8, 5, 7, 6],\n...         [5, 8, 4, 6, 9, 7, 2, 3, 1]]\n>>> sudoku_win_np(np.array(good_board_3x3, dtype=int))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bad_board_3x3 = np.arange(81).reshape(9, 9)\n>>> sudoku_win_np(bad_board_3x3)\nFalse",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bad_board_2x2 = np.array([[1, 1, 2, 4], [2, 4, 3, 1], [4, 2, 1, 3], [1, 3, 4, 2]])\n>>> sudoku_win_np(bad_board_2x2)\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2a": {
     "name": "2a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ans = np.array([0, 0, 0, 0, 1, 1, 1, 2, 2, 2])\n>>> X = np.array([[-1], [0.5], [1], [1.3], [1.6], [2], [2.3], [2.7], [3], [100]])\n>>> C = np.array([[1], [2], [3]])\n>>> np.testing.assert_allclose(nearest_cluster(X, C), ans)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X = np.array([[-101, 1], [1,1], [1, 1.01], [1.5, 1.6], [2.5, -3], [2.5, 2.7], [3, 33]])\n>>> C = np.array([[1, 1], [2,2], [3,3]])\n>>> ans = np.array([0, 0, 0, 1, 0, 2, 2])\n>>> np.testing.assert_allclose(nearest_cluster(X, C), ans)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2b": {
     "name": "2b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import numpy as np\n>>> np.random.seed(1)\n>>> X = np.random.rand(30, 2)\n>>> a = np.random.randint(0, 5, size=30)\n>>> assert compute_centroids(X, a).shape == (5, 2)\n>>> assert np.allclose(X[a == 0].mean(axis=0), compute_centroids(X, a)[0])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2c": {
     "name": "2c",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import numpy as np\n>>> \n>>> np.random.seed(1)\n>>> X = np.random.rand(30, 4)\n>>> k = 2\n>>> rng = np.random.default_rng(12345)\n>>> assert kmeanspp(X, k, rng).shape == (2, 4)\n>>> ans = np.array([[0.87638915, 0.89460666, 0.08504421, 0.03905478], [0.6634415 , 0.62169572, 0.11474597, 0.94948926]])\n>>> np.testing.assert_allclose(kmeanspp(X, k, rng), ans)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2d": {
     "name": "2d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X = np.arange(9).reshape(3, 3)\n>>> a = np.arange(3)\n>>> C = 2 + X\n>>> np.testing.assert_allclose(V(X, a, C), 36)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
