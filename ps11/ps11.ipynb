{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"ps11.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d19a8b5c557678ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem Set 11: Introduction to Pytorch\n",
    "For the final problem set of the semester, you will learn to use the deep learning framework PyTorch. Instructions for installing it are located [here](https://pytorch.org/get-started/locally/). You will also need to install the `torchvision` module using pip.\n",
    "\n",
    "A few notes on this problem set:\n",
    "- Neural networks can potentially take a very long time to train. You are responsible for ensuring that your uploaded solution runs without timing out on the autograder. We have verified that it is possible to do this and receive full credit.\n",
    "- Questions 1c and 2b are worth three points. You get one point if your network has >70% test accuracy; 2 points for >75%; and 3 points for >80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe660c460f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "rng_seed = 507\n",
    "torch.manual_seed(rng_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the Fashion MNIST dataset, which consists of 28x28 images that could be 10 different articles of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to view a random sample from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "# for i in range(1, cols * rows + 1):\n",
    "#     sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "#     img, label = training_data[sample_idx]\n",
    "#     figure.add_subplot(rows, cols, i)\n",
    "#     plt.title(labels_map[label])\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(255 - img.squeeze(), cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some helper functions used throughout this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, transform_fn, loss_fn, optimizer, dataloader, num_epochs):\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for _ in tbar:\n",
    "        loss_total = 0.\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = transform_fn(x)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y.squeeze(-1))\n",
    "            ## Parameter updates\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_total += loss.item()\n",
    "        tbar.set_description(f\"Train loss: {loss_total/len(dataloader)}\")\n",
    "        \n",
    "    return loss_total/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_accuracy(model, transform_fn, test_dataloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    tf = nn.Flatten()\n",
    "    for (xi, yi) in test_dataloader:\n",
    "        xi = transform_fn(xi)\n",
    "        pred = model(xi)\n",
    "        yi_pred = pred.argmax(-1)\n",
    "        y_true.append(yi)\n",
    "        y_pred.append(yi_pred)\n",
    "    y_true = torch.cat(y_true, dim = 0)\n",
    "    y_pred = torch.cat(y_pred, dim = 0)\n",
    "\n",
    "    accuracy = (y_true == y_pred).float().mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1(a)** On PS10 you implemented a multilayer-perceptron (MLP) using JAX. Now you will implement it using PyTorch, and train it to classify images.\n",
    "\n",
    "Recall that an MLP consists of an input layer, an activation function, and another output layer. Write a class called `MultiClassMLP` that subclasses `nn.Module`. This module contains one attribute, `net`, which is an nn.Sequential object that is called on the `.forward(x)` method. \n",
    "Your task is to write the `__init__()` method to correctly construct `net`. \n",
    "\n",
    "For example, if `num_features=784, num_hidden=256, num_classes=10`:\n",
    "\n",
    "```\n",
    ">>> mlp = MultiClassMLP(28**2, 256, 10)\n",
    ">>> mlp.net\n",
    "\n",
    "Sequential(\n",
    "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
    "  (1): Sigmoid()\n",
    "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
    "  (3): LogSoftmax(dim=-1)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiClassMLP(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_classes):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            num_features: The number of features in the input.\n",
    "            num_hidden: Number of hidden features in the hidden layer:\n",
    "            num_classes: Number of possible classes in the output\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                nn.Linear(num_features, num_hidden,bias=True),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(num_hidden, num_classes,bias=True),\n",
    "                nn.LogSoftmax(dim=-1)\n",
    "                )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MultiClassMLP(28**2, 256, 10)\n",
    "isinstance(mlp, nn.Module)\n",
    "isinstance(mlp.net, nn.Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1a results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**1(b)** Construct a `DataLoader` object of the Fashion MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "                                training_data, batch_size=128\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fe640ce2f10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**1(c)** Initialize a `MultiClassMLP` object called `mlp` and train it using the `train_loop()` function given at the beginning of the assignment (do not modify the `train_loop()` function). We will test your trained `mlp` object on unseen test data.\n",
    "\n",
    "Hints:\n",
    "-  You need to initialize a `torch.optim.Optimizer` object for gradient descent. The standard choice is `torch.optim.Adam` with a learning rate `1e-3`.\n",
    "-  You need to flatten the Fashion MNIST dataset to use within the `MultiClassMLP`. This should be done with the `transform_fn` argument to `train_loop`. Try `nn.Flatten()`.\n",
    "-  The output of `MultiClassMLP` are the log probabilities of each class. To test the accuracy of your model, you should use the negative log-likelihood loss, `nn.NLLLoss()`, as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1183923603549822: 100%|██████████| 30/30 [02:15<00:00,  4.50s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1183923603549822"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MultiClassMLP(784,256,10)\n",
    "mlp_optimizer = torch.optim.Adam(mlp.parameters(),lr=0.003) \n",
    "train_loop(model=mlp, transform_fn=nn.Flatten(), loss_fn=nn.NLLLoss(), optimizer=mlp_optimizer, \n",
    "           dataloader=train_dataloader, num_epochs=30)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassMLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
      "    (3): LogSoftmax(dim=-1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "logistic_test_dataloader = DataLoader(test_data, batch_size=1000, shuffle=True, num_workers=0)\n",
    "accuracy = calculate_test_accuracy(mlp, nn.Flatten(), logistic_test_dataloader)\n",
    "accuracy >0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1c results: All test cases passed!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 2: ConvNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**2(a)** Convolutional Neural Networks (CNNs) are neural networks that take advantage of spatial structure in input such as images. This often leads to better efficiency than MLPs.\n",
    "\n",
    "Write a class called `MultiClassConvNet`, which adds convolutional layers to the MLP in Problem 1. Just like `MultiClassMLP`, your class should have a single attribute called `net` of type `nn.Sequential` that is called in the forward method.\n",
    "`convnet.net` should have the following structure:\n",
    "```\n",
    ">>> convnet = MultiClassConvNet(\n",
    "    side_length=28,\n",
    "    conv_channels_1=64,\n",
    "    conv_channels_2=32,\n",
    "    linear_hidden=256,\n",
    "    num_classes=10\n",
    ")\n",
    ">>> convnet.net\n",
    "Sequential(\n",
    "  (0): Conv2d(...)\n",
    "  (1): MaxPool2d(...)\n",
    "  (2): ReLU()\n",
    "  (3): Conv2d(...)\n",
    "  (4): MaxPool2d(...)\n",
    "  (5): ReLU()\n",
    "  (6): Flatten(...)\n",
    "  (7): Linear(...)\n",
    "  (8): ReLU()\n",
    "  (9): Linear(..., out_features=10)\n",
    "  (10): LogSoftmax(dim=-1)\n",
    ")\n",
    "```\n",
    "\n",
    "There are various parameters that must be supplied to each layer. Your job is to experiment with them and understand how they affect classification accuracy. \n",
    "\n",
    "Hint: To calculate the size of `in_features` for the first `Linear` layer, you need to keep track of how each `Conv2d` and `MaxPool2d` change the image dimensions. We provide the function `conv_out_size` to help with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_out_size(slen, kernel_size, stride):\n",
    "    return int((slen - kernel_size) / stride + 1)\n",
    "\n",
    "class MultiClassConvNet(torch.nn.Module):\n",
    "    def __init__(self, side_length, conv_channels_1, conv_channels_2, linear_hidden, num_classes):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            side_length: Side-length of input images (assumed to be square)\n",
    "            conv_channels_1: Number of channels output from first conv layer\n",
    "            conv_channels_2: Number of channels output from second conv layer\n",
    "            linear_hidden: Number of hidden units in linear layer\n",
    "            num_classes: Number of classes in output\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "                nn.Conv2d(1, conv_channels_1,kernel_size=3,stride=1,padding=0),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2,padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(conv_channels_1,conv_channels_2,kernel_size=4,stride=1,padding=0),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2,padding=0),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(conv_channels_2*5*5,linear_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(linear_hidden, num_classes),\n",
    "                nn.LogSoftmax(dim=-1)\n",
    "                )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = MultiClassConvNet(side_length=28, conv_channels_1=64, conv_channels_2=32, linear_hidden=256, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2a results: All test cases passed!"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2(b)** Initialize a `MultiClassConvNet` object called `convnet` and train it using the `train_loop` function as in Problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "                                training_data, batch_size=30\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/var/folders/kd/j4p78gwx537ck9cp75k42y380000gn/T/ipykernel_20868/4134762961.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = transform_fn(x)\n",
      "Train loss: 0.2158765374980867: 100%|██████████| 5/5 [05:35<00:00, 67.03s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2158765374980867"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnet = MultiClassConvNet(side_length=28, conv_channels_1=64, conv_channels_2=32, linear_hidden=256, num_classes=10)\n",
    "\n",
    "convnet_optimizer = torch.optim.Adam(convnet.parameters(),lr=0.003) \n",
    "\n",
    "train_loop(model=convnet, transform_fn=torch.tensor, loss_fn=nn.NLLLoss(), optimizer=convnet_optimizer, \n",
    "           dataloader=train_dataloader, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2b</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2b results: All test cases passed!"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1a results: All test cases passed!\n",
       "\n",
       "q1c results: All test cases passed!\n",
       "\n",
       "q2a results: All test cases passed!\n",
       "\n",
       "q2b results: All test cases passed!"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Upload this .zip file to Gradescope for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <p>Your submission has been exported. Click <a href=\"ps11_2022_04_17T14_18_33_526330.zip\" download=\"ps11_2022_04_17T14_18_33_526330.zip\" target=\"_blank\">here</a>\n",
       "            to download the zip file.</p>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "meta-shift-y"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "otter": {
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> mlp = MultiClassMLP(28**2, 256, 10)\n>>> assert isinstance(mlp, nn.Module)\n>>> assert isinstance(mlp.net, nn.Sequential)\n>>> assert isinstance(mlp.net[0], nn.Linear)\n>>> assert mlp.net[0].in_features == 28 ** 2\n>>> assert mlp.net[0].out_features == 256\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n>>> logistic_test_dataloader = DataLoader(test_data, batch_size=1000, shuffle=True, num_workers=0)\n>>> accuracy = calculate_test_accuracy(mlp, nn.Flatten(), logistic_test_dataloader)\n>>> assert accuracy > 0.75\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n>>> logistic_test_dataloader = DataLoader(test_data, batch_size=1000, shuffle=False, num_workers=0)\n>>> accuracy = calculate_test_accuracy(mlp, nn.Flatten(), logistic_test_dataloader)\n>>> assert accuracy > 0.80\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n>>> logistic_test_dataloader = DataLoader(test_data, batch_size=1000, shuffle=False, num_workers=0)\n>>> accuracy = calculate_test_accuracy(mlp, nn.Flatten(), logistic_test_dataloader)\n>>> assert accuracy > 0.85\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> convnet = MultiClassConvNet(side_length=28, conv_channels_1=8, conv_channels_2=16, linear_hidden=256, num_classes=10)\n>>> assert isinstance(convnet, nn.Module)\n>>> assert isinstance(convnet.net, nn.Sequential)\n>>> assert isinstance(convnet.net[0], nn.Conv2d)\n>>> assert isinstance(convnet.net[1], nn.MaxPool2d)\n>>> assert isinstance(convnet.net[2], nn.ReLU)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> test_data = datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor())\n>>> logistic_test_dataloader = DataLoader(test_data, batch_size=1000, shuffle=True, num_workers=0)\n>>> accuracy = calculate_test_accuracy(convnet, nn.Identity(), logistic_test_dataloader)\n>>> assert accuracy > 0.75\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test_data = datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor())\n>>> logistic_test_dataloader = DataLoader(test_data, batch_size=1000, shuffle=True, num_workers=0)\n>>> accuracy = calculate_test_accuracy(convnet, nn.Identity(), logistic_test_dataloader)\n>>> assert accuracy > 0.80\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test_data = datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor())\n>>> logistic_test_dataloader = DataLoader(test_data, batch_size=1000, shuffle=True, num_workers=0)\n>>> accuracy = calculate_test_accuracy(convnet, nn.Identity(), logistic_test_dataloader)\n>>> assert accuracy > 0.85\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
